{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks from Scratch - P.4 Batches, Layers, and Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch\n",
    "* What is batch? Send sets of inputs (ensemble) to the neuron instead of one set of input at a time. \n",
    "* Why batch? Faster processing. Helps with generalisations (multiple samples at a time).\n",
    "* **We may overfit if we give all samples at once. We still have to maintain the set structure (batches) while feeding the neuron with input.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# batch the input\n",
    "inputs = np.array([[1, 2, 3, 2.5], \n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# we have 4 input values per node\n",
    "# 3 nodes in total\n",
    "# the total number of params that the NN takes is now 4*3 = 12\n",
    "\n",
    "# weights and biases are associated to the neuron\n",
    "# so dont have to inc it.\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1.0], \n",
    "           [0.5, -0.91, 0.26, -0.5], \n",
    "           [-0.26, -0.27, 0.17, 0.87]] )\n",
    "\n",
    "bias = np.array([2, 3, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List comprehension and loop over each neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,3): # number of inputs\n",
    "    output.append([sum([inputs[x][i]*weights[n][i] for i in range(4)])\\\n",
    "             + bias[n] for n in range(n_nodes)])\n",
    "# %%timeit \n",
    "# 90.2 µs ± 1.78 µs per loop\n",
    "# (mean ± std. dev. of 7 runs, 10000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.8, 1.21, 2.385], [8.9, -1.8099999999999996, 0.19999999999999996], [1.4100000000000001, 1.0509999999999997, 0.025999999999999912]]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy and list comprehension at equal exec speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4) and (3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(weights.shape,'and',inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a 3x3 matrix as result to add with the node bias. So change order, take transpose of weights (matrix product)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 98 µs, sys: 5 µs, total: 103 µs\n",
      "Wall time: 90.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "output_np = np.dot(inputs, weights.T) + bias\n",
    "# row by row dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "print(output_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new layer of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use output of previous layer as input for this one. So we have a 3*3 matrix as input for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_output = output_np[:] # copy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this layer has 3 nodes and each layer gets 3 feature inputs\n",
    "weights2 = np.array([[0.1, 0.14, 0.5], \n",
    "           [0.5, 0.12, -0.33], \n",
    "           [-0.44, 0.73, -0.13]])\n",
    "bias2 = np.array([-1, 2, -0.5]) # each node has its own bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2_output = np.dot(layer1_output,weights2.T) + bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8419   3.75815 -2.03875]\n",
      " [-0.2634   6.1668  -5.7633 ]\n",
      " [-0.69886  2.82254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "print(layer2_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit untidy, so convert them into objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object oriented layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch the input\n",
    "X = np.array([[1, 2, 3, 2.5], \n",
    "             [2.0, 5.0, -1.0, 2.0],\n",
    "             [-1.5, 2.7, 3.3, -0.8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we need to do feature scaling, for faster convergence.\n",
    "\n",
    "Also need to init the biases (non zero) and weights (ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights=np.random.randn(n_inputs,n_neurons)\n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do it like this to skip the transpose step. `self.weights=np.random.randn(n_inputs,n_neurons)`\n",
    "(need a weights array (random ndarray) of the size that goes with the input array.) \n",
    "\n",
    "But I like doing transposes, so making it the original way.\n",
    "\n",
    "#### Normalisations\n",
    "Multiply by 0.1 to make the weights smaller than 1\n",
    "\n",
    "We also can optimise by doing feature scaling. \n",
    "`(xi-mean(x))/std(x)` where `x` is a feature from all the neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights=0.1*np.random.randn(n_neurons,n_inputs)\n",
    "        self.biases=np.zeros((1,n_neurons)) # 1D bias\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs,self.weights.T) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = layer(4,3) # no of features x no of neurons in the layer\n",
    "layer2 = layer(3,2) # no of features from output of layer 1 x n neurons\n",
    "layer3 = layer(2,1) # one neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No of features from output of layer 1 = no of neurons in previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.forward(X) # forward prop with first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.11028137  0.23848745  0.47857926]\n",
      " [ 0.90319391 -0.24040763  0.46110582]\n",
      " [-0.01285333 -0.21836097  0.05753692]]\n"
     ]
    }
   ],
   "source": [
    "print(layer1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2.forward(layer1.output) # give out of layer 1 to layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10864077  0.0628607 ]\n",
      " [ 0.0862781  -0.01524151]\n",
      " [-0.00108124 -0.03423416]]\n"
     ]
    }
   ],
   "source": [
    "print(layer2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00196771]\n",
      " [ 0.00400286]\n",
      " [ 0.00289007]]\n"
     ]
    }
   ],
   "source": [
    "layer3.forward(layer2.output)\n",
    "print(layer3.output) # final layer took two features and gave one feature output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
